{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do-sampler Introduction\n",
    "by Adam Kelleher\n",
    "\n",
    "The \"do-sampler\" is a new feature in do-why. While most potential-outcomes oriented estimators focus on estimating the specific contrast $E[Y_0 - Y_1]$, Pearlian inference focuses on more fundamental quantities like the joint distribution of a set of outcomes Y, $P(Y)$, which can be used to derive other statistics of interest.\n",
    "\n",
    "Generally, it's hard to represent a probability distribution non-parametrically. Even if you could, you wouldn't want to gloss over finite-sample problems with you data you used to generate it. With these issues in mind, we decided to represent interventional distributions by sampling from them with an object called to \"do-sampler\". With these samples, we can hope to compute finite-sample statistics of our interventional data. If we bootstrap many such samples, we can even hope for good sampling distributions for these statistics. \n",
    "\n",
    "The user should note that this is still an area of active research, so you should be careful about being too confident in bootstrapped error bars from do-samplers.\n",
    "\n",
    "Note that do samplers sample from the outcome distribution, and so will vary significantly from sample to sample. To use them to compute outcomes, it's recommended to generate several such samples to get an idea of the posterior variance of your statistic of interest.\n",
    "\n",
    "## Pearlian Interventions\n",
    "\n",
    "Following the notion of an intervention in a Pearlian causal model, our do-samplers implement a sequence of steps:\n",
    "\n",
    "1. Disrupt causes\n",
    "2. Make Effective\n",
    "3. Propagate and sample\n",
    "\n",
    "In the first stage, we imagine cutting the in-edges to all of the variables we're intervening on. In the second stage, we set the value of those variables to their interventional quantities. In the third stage, we propagate that value forward through our model to compute interventional outcomes with a sampling procedure.\n",
    "\n",
    "In practice, there are many ways we can implement these steps. They're most explicit when we build the model as a linear bayesian network in PyMC3, which is what underlies the MCMC do sampler. In that case, we fit one bayesian network to the data, then construct a new network representing the interventional network. The structural equations are set with the parameters fit in the initial network, and we sample from that new network to get our do sample.\n",
    "\n",
    "In the weighting do sampler, we abstractly think of \"disrupting the causes\" by accounting for selection into the causal state through propensity score estimation. These scores contain the information used to block back-door paths, and so have the same statistics effect as cutting edges into the causal state. We make the treatment effective by selecting the subset of our data set with the correct value of the causal state. Finally, we generated a weighted random sample using inverse propensity weighting to get our do sample.\n",
    "\n",
    "There are other ways you could implement these three steps, but the formula is the same. We've abstracted them out as abstract class methods which you should override if you'd like to create your own do sampler!\n",
    "\n",
    "## Statefulness\n",
    "\n",
    "The do sampler when accessed through the high-level pandas API is stateless by default.This makes it intuitive to work with, and you can generate different samples with repeated calls to the `pandas.DataFrame.causal.do`. It can be made stateful, which is sometimes useful. \n",
    "\n",
    "The 3-stage process we mentioned before is implemented by passing an internal `pandas.DataFrame` through each of the three stages, but regarding it as temporary. The internal dataframe is reset by default before returning the result.\n",
    "\n",
    "It can be much more efficient to maintain state in the do sampler between generating samples. This is especially true when step 1 requires fitting an expensive model, as is the case with the MCMC do sampler, the kernel density sampler, and the weighting sampler. \n",
    "\n",
    "Instead of re-fitting the model for each sample, you'd like to fit it once, and then generate many samples from the do sampler. You can do this by setting the kwarg `stateful=True` when you call the `pandas.DataFrame.causal.do` method. To reset the state of the dataframe (deleting the model as well as the internal dataframe), you can call the `pandas.DataFrame.causal.reset` method.\n",
    "\n",
    "Through the lower-level API, the sampler is stateful by default. The assumption is that a \"power user\" who is using the low-level API will want more control over the sampling process. In this case, state is carried by internal dataframe `self._df`, which is a copy of the dataframe passed on instantiation. The original dataframe is kept in `self._data`, and is used when the user resets state. \n",
    "\n",
    "## Integration\n",
    "\n",
    "The do-sampler is built on top of the identification abstraction used throughout do-why. It uses a `dowhy.CausalModel` to perform identification, and builds any models it needs automatically using this identification.\n",
    "\n",
    "## Specifying Interventions\n",
    "\n",
    "There is a kwarg on the `dowhy.do_sampler.DoSampler` object called `keep_original_treatment`. While an intervention might be to set all units treatment values to some specific value, it's often natural to keep them set as they were, and instead remove confounding bias during effect estimation. If you'd prefer not to specify an intervention, you can set the kwarg like `keep_original_treatment=True`, and the second stage of the 3-stage process will be skipped. In that case, any intervention specified on sampling will be ignored.\n",
    "\n",
    "If the `keep_original_treatment` flag is set to false (it is by default), then you must specify an intervention when you sample from the do sampler. For details, see the demo below!\n",
    "\n",
    "\n",
    "## Demo\n",
    "\n",
    "First, let's generate some data and a causal model. Here, Z confounds our causal state, D, with the outcome, Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dowhy.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "\n",
    "z = np.random.uniform(size=N)\n",
    "d = np.random.binomial(1., p=1./(1. + np.exp(-5. * z)))\n",
    "y = 2. * z + d + 0.1 * np.random.normal(size=N)\n",
    "\n",
    "df = pd.DataFrame({'Z': z, 'D': d, 'Y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle 1.6110641638748924$"
      ],
      "text/plain": [
       "1.6110641638748924"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[df.D == 1].mean() - df[df.D == 0].mean())['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the naive effect is around 60% high. Now, let's build a causal model for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dowhy.causal_model:Causal Graph not provided. DoWhy will construct a graph based on data inputs.\n",
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['D'] on outcome ['Y']\n"
     ]
    }
   ],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "causes = ['D']\n",
    "outcomes = ['Y']\n",
    "common_causes = ['Z']\n",
    "\n",
    "model = CausalModel(df, \n",
    "                    causes,\n",
    "                    outcomes,\n",
    "                    common_causes=common_causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, we can try to identify the causal effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Z', 'U']\n",
      "WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n"
     ]
    }
   ],
   "source": [
    "identification = model.identify_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification works! We didn't actually need to do this yet, since it will happen internally with the do sampler, but it can't hurt to check that identification works before proceeding. Now, let's build the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amit/python-virtual-envs/env/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['Z', 'U']\n",
      "WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n",
      "INFO:dowhy.do_sampler:Using WeightingSampler for do sampling.\n",
      "INFO:dowhy.do_sampler:Caution: do samplers assume iid data.\n"
     ]
    }
   ],
   "source": [
    "from dowhy.do_samplers.weighting_sampler import WeightingSampler\n",
    "\n",
    "sampler = WeightingSampler(df,\n",
    "                           causal_model=model,\n",
    "                           keep_original_treatment=True,\n",
    "                           variable_types={'D': 'b', 'Z': 'c', 'Y': 'c'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can just sample from the interventional distribution! Since we set the `keep_original_treatment` flag to `False`, any treatment we pass here will be ignored. Here, we'll just pass `None` to acknowledge that we know we don't want to pass anything.\n",
    "\n",
    "If you'd prefer to specify an intervention, you can just put the interventional value here instead as a list or numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventional_df = sampler.do_sample(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle 0.9725034481600202$"
      ],
      "text/plain": [
       "0.9725034481600202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(interventional_df[interventional_df.D == 1].mean() - interventional_df[interventional_df.D == 0].mean())['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're much closer to the true effect, which is around 1.0!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dowhy",
   "language": "python",
   "name": "dowhy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
